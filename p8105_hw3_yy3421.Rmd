---
title: "p8105_hw3_yy3421"
output: github_document
---

## Problem 1
Loading dataset:

```{r}
library(tidyverse)
library(ggridges)
library(patchwork)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
library(p8105.datasets)
data("instacart")

theme_set(theme_minimal() + theme(legend.position = "right"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

### Question 1:

Group by aisle:

```{r}
instacart_aisle = instacart |> 
  group_by(aisle)
```

```{r}
n_item_max = instacart_aisle |> 
  summarise(n_item=n()) |> 
  arrange(desc(n_item))
```

There are `r instacart_aisle |> summarize() |> nrow()` aisles. The most items are ordered from aisle "`r n_item_max$aisle[1]`" with `r n_item_max$n_item[1]` items.

### Question 2:
```{r}
n_item_max |> 
  filter(
    n_item > 10000
  ) |> 
  ggplot(aes(x= reorder(aisle, +n_item), y = n_item))+
  geom_point() +
  labs(
    y = "Aisle",
    x = "Number of Items",
    caption = "Number of Items for Each Aisle with More than 10,000 Items"
  )+
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

This point plot shows the number of items ordered in each aisle in an ascending order.

### Question 3:
```{r}
instacart_aisle |> 
  group_by(aisle, product_name) |> 
  filter(
      aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits"
    ) |> 
  summarize(n_product = n()) |> 
  arrange(desc(n_product)) |> 
  mutate(
    product_rank = min_rank(desc(n_product))
    ) |> 
  filter(product_rank < 4) |> 
  knitr::kable()

```

The above table table shows the three most popular items in aisles `baking ingredients`, `dog food care`, and `packaged vegetables fruits`, and  the number of times each item is ordered.

### Question 4:
```{r}
instacart |> 
  group_by(order_dow, product_name) |> 
  filter(
    product_name == "Pink Lady Apples"| product_name == "Coffee Ice Cream"
  ) |> 
  summarize(
    mean_hour = mean(order_hour_of_day)
  ) |> 
  mutate(
    order_dow = order_dow +1
  ) |> 
  pivot_wider(
    names_from = product_name,
    values_from = mean_hour
  ) |> 
  knitr::kable(digits = 2)
```

The last table shows the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on every single day of the week. Pink Lady Apples are generally purchased slightly earlier in the day than Coffee Ice Cream, with the exception of day 5.

## Problem 2

Load data and clean:

```{r}
library(p8105.datasets)
data("brfss_smart2010")
```

Data cleaning:
```{r}
brfss_smart2010 = 
  brfss_smart2010 |> 
  janitor::clean_names() |> 
  rename(state = locationabbr, county = locationdesc) |> 
  filter(
    topic == "Overall Health",
    response == "Excellent"|response == "Very good"|response == "Good"|response == "Fair"|response == "Poor"
  ) |> 
  mutate(
    response = ordered(response, levels = c("Excellent", "Very good", "Good", "Fair", "Poor"))
  ) |> 
  arrange(desc(response))
```

### Question 1:


```{r}
brfss_smart2002_state = 
  brfss_smart2010 |> 
  filter(
    year == 2002
  ) |> 
  group_by(state) |> 
  summarize(n_location = n_distinct(county)) |> 
  filter(
    n_location >= 7
  )

str(brfss_smart2002_state)

brfss_smart2010_state = 
  brfss_smart2010 |> 
  filter(
    year == 2010
  ) |> 
  group_by(state) |> 
  summarize(n_location = n_distinct(county)) |> 
  filter(
    n_location >= 7)

str(brfss_smart2010_state)
```

There are `r nrow(brfss_smart2002_state)` locations in 2002, which are CT, FL, MA, NC, NJ, PA.

There are `r nrow(brfss_smart2010_state)` locations in 2010, which are CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, WA.

### Question 2:

```{r}
brfss_excellent_avg =
  brfss_smart2010 |> 
  filter(
    response == "Excellent"
  ) |> 
  select(year, state, data_value
  ) |> 
  group_by(state, year) |> 
  summarize(avg_data_value = mean(data_value, na.rm = TRUE)) 

brfss_excellent_avg |> 
  ggplot(aes(
    x = year, 
    y = avg_data_value, 
    color = state,
    group = state))+
  geom_point()+
  geom_line()+
  labs(
    x = "Year",
    y = "Average Data Values",
    caption = "Change in Average Data Values from 2002 to 2010 for Each State"
  )
```

The `brfss_excellent_avg` data set contains only the information on the state with `Excellent` responses. In this data set, the three variables are `state`, `year`, and `avg_data_value`. Based on these three variables, this dataset contains information on the average data values of each state with `Excellent` reponse every year.

The plot above shows the change in average data values of each state, only with Excellent responses, per year during the time period of 2002 to 2010. We can observe that each state has an obvious change in average data value per year.

### Question 3:

```{r}
brfss_smart2010 |> 
  filter(
    state == "NY",
    year == 2006 | year == 2010
  ) |> 
  ggplot(
    aes(
      x = response, y = data_value, fill = response
    )
  )+
  geom_boxplot()+
  facet_grid(~year)+
  labs(
    x = "Response",
    y = "Data Value",
    caption = "Distribution of Data Value for Responses between 2006 and 2010"
  )
```

The above two-panel plot compare the data value between year 2006 and 2010. In each year, the data value is further grouped based on the response, `Excellent`, `Very good`, `Good`, `Fair`, and `Poor`. Based on this plot, in 2006, responses `Very good` and `Good` have the highest data values while response `Very good` has the highest data values in 2010. However, both years have `Poor` as the lowest data value response.

## Problem 3

Cleaning and merging the two csv:

```{r}
nhanes_accel = 
  read_csv("data/nhanes_accel.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    min1:min1440,
    names_to = "number_of_time",
    values_to = "activity_time",
    names_prefix = "min"
  )


nhanes_covar = 
  read_csv("data/nhanes_covar.csv", skip = 4) |> 
  janitor::clean_names() |> 
  filter(
    age>=21,
    is.na(bmi) == FALSE,
    is.na(education) == FALSE
  ) |> 
   mutate(
    sex = 
      case_match(
        sex,
        1 ~ "male",
        2 ~ "female"),
    sex = as.factor(sex),
    education =
      case_match(
        education,
        1 ~ "less than high school",
        2 ~ "high school equivalent",
        3 ~ "more than high school"),
    education = as.factor(education))

nhanes_df = 
  left_join(nhanes_covar, nhanes_accel, by = "seqn")
```

### Question 1: 
Produce a reader-friendly table for the number of men and women in each education category, and create a visualization of the age distributions for men and women in each education category. 

Table:
```{r}
nhanes_covar |> 
  group_by(education, sex) |> 
  summarise(number =n()) |> 
  knitr::kable()

```

The table above shows the number of people in each educaiton and sex category. Based on this table, most of female and male have an education level of `more than high school`.

Visualization of Age Distribution:
```{r}
nhanes_covar |> 
  ggplot(aes(x = age, fill = sex))+
  geom_density(alpha=.5)+
  facet_grid(.~ education)+
  labs(
    x = "Age",
    y = "Distribution",
    caption = "Age Distribution of Men and Women in Each Education Category"
  )
```

The three-panel density plot above presents the age distribution for men and women in each education category. In education levels `high school equivalent` and `less than high school`, female has a left-skewed and comparatively unimodal distribution. In these two education levels, male has a bimodel distribution and comparatively left-skewed distribution for `less than high school`. For `more than high school`, both sex categories have a right-skewed distribution.

### Question 2:
Traditional analyses of accelerometer data focus on the total activity over the day. Using your tidied dataset, aggregate across minutes to create a total activity variable for each participant. Plot these total activities (y-axis) against age (x-axis); your plot should compare men to women and have separate panels for each education level. Include a trend line or a smooth to illustrate differences. Comment on your plot.

```{r}
nhanes_df |> 
  group_by(seqn, sex, age, education) |> 
  summarize(total_activity = sum(activity_time)) |> 
  ggplot(aes(x = age, y = total_activity, color = sex))+
  geom_point()+
  geom_smooth(se = FALSE)+
  facet_grid(.~ education)+
  labs(
    x = "Age",
    y = "Total Activity over the Day",
    caption = "Total Activities Versus Age of Men and Women for Each Education Level"
  )
```

The three-panel plot above shows the total activity level over the day versus age for each education level. In each education level, the data is grouped and color-coded based on sex. Based on the trend lines in each panel, we can observe a common pattern of an overall decreasing trend in all three education levels as age increases. Furthermore, female has a higher total activity value compared to male in the education levels of `high school equivalent` and `more than high school`.

### Question 3:
Accelerometer data allows the inspection activity over the course of the day. Make a three-panel plot that shows the 24-hour activity time courses for each education level and use color to indicate sex. Describe in words any patterns or conclusions you can make based on this graph; including smooth trends may help identify differences.

```{r}
nhanes_df |> 
  ggplot(aes(x = number_of_time, y = activity_time, group = seqn, color = sex))+
  geom_line(alpha = .2)+
  geom_smooth(aes(group = sex), se = FALSE)+
  facet_grid(.~ education)+
  labs(
    x = "Number of Time",
    y = "Activity Time",
    caption = "24-Hour Activity Time Courses for Each Educaiton Level"
  )
```

In each education level, the above plot shows the 24-hour activity time changes for each participant and is color-coded based on sex. The trend of each participant in every minute in a day is presented in this plot. Overall, the trend line of change in 24 hours is similar in each education level for each sex is similar with a minimum near the middle of day.